{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Section 4 & 5: Experiments and pseudo-experiments</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "import scipy \n",
    "from scipy.linalg import eigh, cholesky\n",
    "from scipy.stats import norm\n",
    "import linearmodels.panel as lmp\n",
    "from pylab import plot, show, axis, subplot, xlabel, ylabel, grid\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we simulate some data to analyze the potential impact of a randomized controlled experiment (RCT). \n",
    "\n",
    "We create the following variables:\n",
    "- three correlated random variables (X1, X2, X3) using the cholesky decomposition method.\n",
    "- treatment status (T)\n",
    "- time variable (p)\n",
    "- cluster or grouping variable (cl)\n",
    "- outcome variable as a function of time and treatment status interaction, plus random heterogeneity (y)\n",
    "\n",
    "Note that you could make random heterogeneity correlated also within groups using the varable *cl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>p</th>\n",
       "      <th>T</th>\n",
       "      <th>cl</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.026132</td>\n",
       "      <td>-0.024901</td>\n",
       "      <td>-0.015886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>15.026427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.876621</td>\n",
       "      <td>2.335915</td>\n",
       "      <td>1.140894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500041</td>\n",
       "      <td>2.872569</td>\n",
       "      <td>18.751313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.178571</td>\n",
       "      <td>-7.798972</td>\n",
       "      <td>-4.620694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-51.895660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.232056</td>\n",
       "      <td>-1.585591</td>\n",
       "      <td>-0.774071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.524385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024851</td>\n",
       "      <td>-0.029248</td>\n",
       "      <td>-0.031575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>14.932051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.275864</td>\n",
       "      <td>1.557381</td>\n",
       "      <td>0.754355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.022460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.124257</td>\n",
       "      <td>7.803660</td>\n",
       "      <td>4.177833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>76.885242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           X3       p            T  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.0  5000.000000   \n",
       "mean      0.026132    -0.024901    -0.015886     1.0     0.503000   \n",
       "std       1.876621     2.335915     1.140894     0.0     0.500041   \n",
       "min      -7.178571    -7.798972    -4.620694     1.0     0.000000   \n",
       "25%      -1.232056    -1.585591    -0.774071     1.0     0.000000   \n",
       "50%       0.024851    -0.029248    -0.031575     1.0     1.000000   \n",
       "75%       1.275864     1.557381     0.754355     1.0     1.000000   \n",
       "max       7.124257     7.803660     4.177833     1.0     1.000000   \n",
       "\n",
       "                cl            y  \n",
       "count  5000.000000  5000.000000  \n",
       "mean      5.500000    15.026427  \n",
       "std       2.872569    18.751313  \n",
       "min       1.000000   -51.895660  \n",
       "25%       3.000000     2.524385  \n",
       "50%       5.500000    14.932051  \n",
       "75%       8.000000    28.022460  \n",
       "max      10.000000    76.885242  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment parameters\n",
    "np.random.seed(123) #set seed\n",
    "nsize = 10000 #sample size\n",
    "\n",
    "# we create simulated data starting from a given variance-covariance matrix\n",
    "\n",
    "# variance-covariance matrix (simetric)\n",
    "cov = np.array([\n",
    "        [  3.40, -2.75, -2.00],\n",
    "        [ -2.75,  5.50,  1.50],\n",
    "        [ -2.00,  1.50,  1.25]\n",
    "    ])\n",
    "\n",
    "X = norm.rvs(size=(3, nsize)) #vector of variables N(0,1)\n",
    "evals, evecs = eigh(cov) #eigenvalues and eigenvector from var-covar matrix\n",
    "c = np.dot(evecs, np.diag(np.sqrt(evals))) #cholesky decomposition\n",
    "Xc = np.dot(c, X) #introduce correlation to matrix X\n",
    "Xc = Xc.transpose() \n",
    "Xc = pd.DataFrame(Xc, columns=['X1','X2','X3']) \n",
    "\n",
    "#time periods and treatment asignment \n",
    "Xc['p'] = 1\n",
    "Xc.loc[0:4999,'p'] = 0\n",
    "tr = np.random.binomial(1, 0.5, size=5000) #treatment status\n",
    "Xc.loc[0:4999,'T'] = tr\n",
    "Xc.loc[5000:9999,'T'] = tr \n",
    " \n",
    "#grouping variable\n",
    "Xc['cl']=1\n",
    "Xc.loc[500:999,'cl']=2\n",
    "Xc.loc[1000:1499,'cl']=3\n",
    "Xc.loc[1500:1999,'cl']=4\n",
    "Xc.loc[2000:2499,'cl']=5\n",
    "Xc.loc[2500:2999,'cl']=6\n",
    "Xc.loc[3000:3499,'cl']=7\n",
    "Xc.loc[3500:3999,'cl']=8\n",
    "Xc.loc[4000:4499,'cl']=9\n",
    "Xc.loc[4500:4999,'cl']=10\n",
    "Xc.loc[5500:5999,'cl']=2\n",
    "Xc.loc[6000:6499,'cl']=3\n",
    "Xc.loc[6500:6999,'cl']=4\n",
    "Xc.loc[7000:7499,'cl']=5\n",
    "Xc.loc[7500:7999,'cl']=6\n",
    "Xc.loc[8000:8499,'cl']=7\n",
    "Xc.loc[8500:8999,'cl']=8\n",
    "Xc.loc[9000:9499,'cl']=9\n",
    "Xc.loc[9500:9999,'cl']=10\n",
    "\n",
    "#outcome variable\n",
    "Xc['y'] = 10*(1+Xc['X1']) + 10*(Xc['X2']+Xc['T']*Xc['p']) + Xc['X3'] \n",
    "\n",
    "#data description\n",
    "Xc.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Controlled Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can estimate the sample size needed for a given effect (power analysis). In this example we estimate a sample size for a standarized effect of 0.2, a signficance of 95% (alpha=0.05), and power of 0.9 (chances of a false negative are 10%).\n",
    "\n",
    "Based on the formula, given an independent sample, we require 526 individuals, divided evenly between treatment and control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 526.000\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "# parameters for power analysis \n",
    "effect = 0.2\n",
    "alpha = 0.05\n",
    "power = 0.9\n",
    "\n",
    "# perform power analysis \n",
    "analysis = TTestIndPower()\n",
    "result = analysis.solve_power(effect, power = power, nobs1= None, ratio = 1.0, alpha = alpha)\n",
    "print('Sample Size: %.3f' % round(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on the data generated we can estimate the treatment effect (post-test only) using OLS and creating some additional variables as needed. We restrict to the data in the second period, when the treatment ocurrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.068\n",
      "Model:                            OLS   Adj. R-squared:                  0.067\n",
      "Method:                 Least Squares   F-statistic:                     362.2\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):           4.96e-78\n",
      "Time:                        13:31:57   Log-Likelihood:                -21576.\n",
      "No. Observations:                5000   AIC:                         4.316e+04\n",
      "Df Residuals:                    4998   BIC:                         4.317e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         10.1229      0.363     27.867      0.000       9.411      10.835\n",
      "T              9.7485      0.512     19.033      0.000       8.744      10.753\n",
      "==============================================================================\n",
      "Omnibus:                        0.156   Durbin-Watson:                   1.930\n",
      "Prob(Omnibus):                  0.925   Jarque-Bera (JB):                0.178\n",
      "Skew:                          -0.012   Prob(JB):                        0.915\n",
      "Kurtosis:                       2.982   Cond. No.                         2.63\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#post-test\n",
    "y = Xc.loc[5000:9999,'y']\n",
    "X = Xc.loc[5000:9999,'T']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate via OLS the treatment effect using differences in differences. We use all the data, and create a variable that represents the interaction between time and treatment status. By construction, treatment status and time variables alone have no impact on the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.055\n",
      "Model:                            OLS   Adj. R-squared:                  0.055\n",
      "Method:                 Least Squares   F-statistic:                     194.2\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):          2.02e-122\n",
      "Time:                        13:32:05   Log-Likelihood:                -43129.\n",
      "No. Observations:               10000   AIC:                         8.627e+04\n",
      "Df Residuals:                    9996   BIC:                         8.629e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          9.6617      0.362     26.657      0.000       8.951      10.372\n",
      "p              0.4613      0.513      0.900      0.368      -0.543       1.466\n",
      "T              0.0407      0.511      0.080      0.936      -0.961       1.042\n",
      "dd             9.7077      0.723     13.432      0.000       8.291      11.124\n",
      "==============================================================================\n",
      "Omnibus:                        0.643   Durbin-Watson:                   1.948\n",
      "Prob(Omnibus):                  0.725   Jarque-Bera (JB):                0.647\n",
      "Skew:                          -0.020   Prob(JB):                        0.724\n",
      "Kurtosis:                       2.996   Cond. No.                         6.87\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#pre-post test\n",
    "y=Xc['y']\n",
    "Xc['dd']= Xc['p']*Xc['T']\n",
    "X=Xc[['p','T','dd']]\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results2 = model.fit()\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we estimate differences in differences but adjusting the standard errors based on the cluster variable. Since we did not create correlation within groups, the differences between both estimators are neglible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.055\n",
      "Model:                            OLS   Adj. R-squared:                  0.055\n",
      "Method:                 Least Squares   F-statistic:                     343.0\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):           1.36e-09\n",
      "Time:                        13:32:15   Log-Likelihood:                -43129.\n",
      "No. Observations:               10000   AIC:                         8.627e+04\n",
      "Df Residuals:                    9996   BIC:                         8.629e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:              cluster                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          9.6617      0.379     25.484      0.000       8.919      10.405\n",
      "p              0.4613      0.341      1.353      0.176      -0.207       1.129\n",
      "T              0.0407      0.503      0.081      0.935      -0.946       1.027\n",
      "dd             9.7077      0.564     17.214      0.000       8.602      10.813\n",
      "==============================================================================\n",
      "Omnibus:                        0.643   Durbin-Watson:                   1.948\n",
      "Prob(Omnibus):                  0.725   Jarque-Bera (JB):                0.647\n",
      "Skew:                          -0.020   Prob(JB):                        0.724\n",
      "Kurtosis:                       2.996   Cond. No.                         6.87\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "#clustered standard errors\n",
    "results3 = model.fit(cov_type=\"cluster\", cov_kwds={'groups': Xc['cl']})\n",
    "print(results3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **charls.csv** we will estimate basic difference estimator (treatment effect), intent to treat, and instrumental variables. The intervention is a public pension (*nrps*) and the outcome variable is retirement status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bnrps</th>\n",
       "      <th>cesd</th>\n",
       "      <th>child</th>\n",
       "      <th>dnrps</th>\n",
       "      <th>female</th>\n",
       "      <th>hrsusu</th>\n",
       "      <th>hsize</th>\n",
       "      <th>intmonth</th>\n",
       "      <th>married</th>\n",
       "      <th>nrps</th>\n",
       "      <th>retage</th>\n",
       "      <th>retired</th>\n",
       "      <th>schadj</th>\n",
       "      <th>urban</th>\n",
       "      <th>wave</th>\n",
       "      <th>wealth</th>\n",
       "      <th>inid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>2.104500e+04</td>\n",
       "      <td>21045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>59.386553</td>\n",
       "      <td>59.610683</td>\n",
       "      <td>8.656878</td>\n",
       "      <td>2.825232</td>\n",
       "      <td>0.740889</td>\n",
       "      <td>0.521026</td>\n",
       "      <td>2.548166</td>\n",
       "      <td>3.585222</td>\n",
       "      <td>7.511143</td>\n",
       "      <td>0.907674</td>\n",
       "      <td>0.519078</td>\n",
       "      <td>1.280969</td>\n",
       "      <td>0.204942</td>\n",
       "      <td>4.162414</td>\n",
       "      <td>0.206652</td>\n",
       "      <td>1.909385</td>\n",
       "      <td>6.783959e+03</td>\n",
       "      <td>12747.082870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.016106</td>\n",
       "      <td>51.905928</td>\n",
       "      <td>6.307677</td>\n",
       "      <td>1.372179</td>\n",
       "      <td>0.438157</td>\n",
       "      <td>0.499570</td>\n",
       "      <td>1.757182</td>\n",
       "      <td>1.720136</td>\n",
       "      <td>0.865851</td>\n",
       "      <td>0.289492</td>\n",
       "      <td>0.499648</td>\n",
       "      <td>3.830963</td>\n",
       "      <td>0.403669</td>\n",
       "      <td>3.540039</td>\n",
       "      <td>0.404914</td>\n",
       "      <td>0.817975</td>\n",
       "      <td>5.453065e+04</td>\n",
       "      <td>7769.025809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.648450e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>5176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>13314.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>74.875404</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.800000e+03</td>\n",
       "      <td>19650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.123964</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.040000e+06</td>\n",
       "      <td>25403.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age         bnrps          cesd         child         dnrps  \\\n",
       "count  21045.000000  21045.000000  21045.000000  21045.000000  21045.000000   \n",
       "mean      59.386553     59.610683      8.656878      2.825232      0.740889   \n",
       "std        9.016106     51.905928      6.307677      1.372179      0.438157   \n",
       "min       20.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       52.000000      0.000000      4.000000      2.000000      0.000000   \n",
       "50%       59.000000     60.000000      7.000000      3.000000      1.000000   \n",
       "75%       65.000000     74.875404     12.000000      4.000000      1.000000   \n",
       "max       95.000000    300.000000     30.000000     10.000000      1.000000   \n",
       "\n",
       "             female        hrsusu         hsize      intmonth       married  \\\n",
       "count  21045.000000  21045.000000  21045.000000  21045.000000  21045.000000   \n",
       "mean       0.521026      2.548166      3.585222      7.511143      0.907674   \n",
       "std        0.499570      1.757182      1.720136      0.865851      0.289492   \n",
       "min        0.000000      0.000000      1.000000      1.000000      0.000000   \n",
       "25%        0.000000      0.000000      2.000000      7.000000      1.000000   \n",
       "50%        1.000000      3.401197      3.000000      7.000000      1.000000   \n",
       "75%        1.000000      4.025352      5.000000      8.000000      1.000000   \n",
       "max        1.000000      5.123964     16.000000     12.000000      1.000000   \n",
       "\n",
       "               nrps        retage       retired        schadj         urban  \\\n",
       "count  21045.000000  21045.000000  21045.000000  21045.000000  21045.000000   \n",
       "mean       0.519078      1.280969      0.204942      4.162414      0.206652   \n",
       "std        0.499648      3.830963      0.403669      3.540039      0.404914   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      4.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      8.000000      0.000000   \n",
       "max        1.000000     51.000000      1.000000     16.000000      1.000000   \n",
       "\n",
       "               wave        wealth          inid  \n",
       "count  21045.000000  2.104500e+04  21045.000000  \n",
       "mean       1.909385  6.783959e+03  12747.082870  \n",
       "std        0.817975  5.453065e+04   7769.025809  \n",
       "min        1.000000 -1.648450e+06      1.000000  \n",
       "25%        1.000000  1.000000e+02   5176.000000  \n",
       "50%        2.000000  1.000000e+03  13314.000000  \n",
       "75%        3.000000  6.800000e+03  19650.000000  \n",
       "max        3.000000  1.040000e+06  25403.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charls = pd.read_csv('../data/charls.csv')\n",
    "charls.dropna(inplace=True)\n",
    "charls.reset_index(drop=True, inplace=True)\n",
    "\n",
    "charls.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ignore the panel nature of the data and estimate the overall effect of pension status on retirement status using a linear probability model. We incoporate control variables that could predict treatment status. \n",
    "\n",
    "Taken all together, pension access reduces the probability to retire by 2.6 percent points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                retired   R-squared:                       0.124\n",
      "Model:                            OLS   Adj. R-squared:                  0.124\n",
      "Method:                 Least Squares   F-statistic:                     530.8\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:47:06   Log-Likelihood:                -9376.5\n",
      "No. Observations:               21045   AIC:                         1.876e+04\n",
      "Df Residuals:                   21039   BIC:                         1.881e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6142      0.025    -24.987      0.000      -0.662      -0.566\n",
      "married       -0.0745      0.011     -6.718      0.000      -0.096      -0.053\n",
      "female         0.1045      0.005     20.137      0.000       0.094       0.115\n",
      "age            0.0143      0.000     43.726      0.000       0.014       0.015\n",
      "hsize         -0.0002      0.002     -0.151      0.880      -0.003       0.003\n",
      "nrps          -0.0260      0.005     -4.971      0.000      -0.036      -0.016\n",
      "==============================================================================\n",
      "Omnibus:                     3404.726   Durbin-Watson:                   1.451\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5359.254\n",
      "Skew:                           1.230   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.254   Cond. No.                         559.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "Xa=charls[['married','female','age','hsize','nrps']]\n",
    "ya=charls['retired']\n",
    "Xa = sm.add_constant(Xa)\n",
    "\n",
    "model = sm.OLS(ya, Xa)\n",
    "results = model.fit(cov_type=\"HC1\")\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrumental Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we estimate the intent-to-treat using the variable that reflects whether the pension is offered or not (dnrps). As noted in the descriptive statistics, the pension is offered to 3/4 of the population, and roughly 2/3 of those are enrolled.\n",
    "\n",
    "As noted, the intent-to-treat (being offered the pension) is not significant to the retiremnt decision. For instrumental variables, this is known as the exclusion restriction (instrument affects treatment status but not outcome). Therefore, *dnrps* is a good candidate as an instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                retired   R-squared:                       0.123\n",
      "Model:                            OLS   Adj. R-squared:                  0.123\n",
      "Method:                 Least Squares   F-statistic:                     526.5\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:47:18   Log-Likelihood:                -9388.0\n",
      "No. Observations:               21045   AIC:                         1.879e+04\n",
      "Df Residuals:                   21039   BIC:                         1.884e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6246      0.025    -25.270      0.000      -0.673      -0.576\n",
      "married       -0.0780      0.011     -7.032      0.000      -0.100      -0.056\n",
      "female         0.1035      0.005     19.937      0.000       0.093       0.114\n",
      "age            0.0142      0.000     43.332      0.000       0.014       0.015\n",
      "hsize      -7.731e-06      0.002     -0.005      0.996      -0.003       0.003\n",
      "dnrps          0.0077      0.006      1.309      0.191      -0.004       0.019\n",
      "==============================================================================\n",
      "Omnibus:                     3413.088   Durbin-Watson:                   1.446\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5378.645\n",
      "Skew:                           1.232   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.252   Cond. No.                         561.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "Xa=charls[['married','female','age','hsize','dnrps']]\n",
    "ya=charls['retired']\n",
    "Xa = sm.add_constant(Xa)\n",
    "\n",
    "model = sm.OLS(ya, Xa)\n",
    "results = model.fit(cov_type=\"HC1\")\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we re-estimate the natural experiment design but using instrumental variables, so we explore the LATE effect, instead of ATE effect. The instrument is implementation date of the policy (*dnrps*).\n",
    "\n",
    "We estimate the first stage, then predict the expected values, and use those (pnrps) instead of actual treatment status (nrps) in the second stage. \n",
    "\n",
    "As expected, the instrument has a significant impact on treatment status. However, results from the second stage indicate that there is no longer a relationship between the pension and retirement status. The Wald estimator for the LATE indicates a positive relationship but not significant.\n",
    "\n",
    "In summary, the ATE effect is negative, however it could be biased because omitted variables that are determining whether individuals access to the pension and retire simulaneously. Once we use an instrument to control for endogeneity, there is no longer a relationship between the pension and retirement in this sample.\n",
    "\n",
    "For additional info see:\n",
    "\n",
    "Parada-Contzen and Caro (2022) Pension Incentives and Retirement Planning in Rural China: Evidence for the New Rural Pension Scheme. https://doi.org/10.1111/deve.12297  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   nrps   R-squared:                       0.378\n",
      "Model:                            OLS   Adj. R-squared:                  0.378\n",
      "Method:                 Least Squares   F-statistic:                     9150.\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:53:41   Log-Likelihood:                -10257.\n",
      "No. Observations:               21045   AIC:                         2.052e+04\n",
      "Df Residuals:                   21040   BIC:                         2.056e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0101      0.023     -0.430      0.667      -0.056       0.036\n",
      "married       -0.0116      0.009     -1.259      0.208      -0.030       0.006\n",
      "female         0.0283      0.005      5.152      0.000       0.018       0.039\n",
      "age         9.153e-05      0.000      0.281      0.779      -0.001       0.001\n",
      "dnrps          0.7012      0.004    188.106      0.000       0.694       0.709\n",
      "==============================================================================\n",
      "Omnibus:                     3275.813   Durbin-Watson:                   1.611\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3947.306\n",
      "Skew:                          -1.016   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.387   Cond. No.                         537.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "Xf=charls[['married','female','age','dnrps']]\n",
    "yf=charls['nrps']\n",
    "Xf = sm.add_constant(Xf)\n",
    "model = sm.OLS(yf, Xf)\n",
    "first = model.fit(cov_type=\"HC1\")\n",
    "charls['pnrps']=first.predict(Xf)\n",
    "\n",
    "print(first.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                retired   R-squared:                       0.123\n",
      "Model:                            OLS   Adj. R-squared:                  0.123\n",
      "Method:                 Least Squares   F-statistic:                     526.5\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        13:53:46   Log-Likelihood:                -9388.0\n",
      "No. Observations:               21045   AIC:                         1.879e+04\n",
      "Df Residuals:                   21039   BIC:                         1.884e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6245      0.025    -25.274      0.000      -0.673      -0.576\n",
      "married       -0.0779      0.011     -7.025      0.000      -0.100      -0.056\n",
      "female         0.1032      0.005     19.870      0.000       0.093       0.113\n",
      "age            0.0142      0.000     43.321      0.000       0.014       0.015\n",
      "hsize      -7.731e-06      0.002     -0.005      0.996      -0.003       0.003\n",
      "pnrps          0.0110      0.008      1.309      0.191      -0.005       0.027\n",
      "==============================================================================\n",
      "Omnibus:                     3413.088   Durbin-Watson:                   1.446\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5378.645\n",
      "Skew:                           1.232   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.252   Cond. No.                         561.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "Xa=charls[['married','female','age','hsize','pnrps']]\n",
    "ya=charls['retired']\n",
    "Xa = sm.add_constant(Xa)\n",
    "model = sm.OLS(ya, Xa)\n",
    "second = model.fit(cov_type=\"HC1\")\n",
    "\n",
    "print(second.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015658522589718157"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second.params['pnrps']/first.params['dnrps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "## Event study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the simulated data from the first section, we will explore the estimator for event study design. We create a dataset with 10 periods (determined by the time trend *cl*). In this setup, the variable y is a function of variables X1, X2 and time trend. Also, there is a treatment effect that increases only in the last two periods, when the intervention is active. To do this, we create a variable named Tc which reflects the additional effect due to treatment, interacted with the time period.\n",
    "\n",
    "By construction, there is a time effect, that increases after treatment, which is identified in the coefficient for the *Tc* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>T</th>\n",
       "      <th>cl</th>\n",
       "      <th>y</th>\n",
       "      <th>Tc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.026132</td>\n",
       "      <td>-0.024901</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>25.201627</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.876621</td>\n",
       "      <td>2.335915</td>\n",
       "      <td>0.40004</td>\n",
       "      <td>2.872569</td>\n",
       "      <td>18.412630</td>\n",
       "      <td>3.806954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.178571</td>\n",
       "      <td>-7.798972</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-23.692425</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.232056</td>\n",
       "      <td>-1.585591</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.262571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024851</td>\n",
       "      <td>-0.029248</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>22.595764</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.275864</td>\n",
       "      <td>1.557381</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>35.658769</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.124257</td>\n",
       "      <td>7.803660</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>91.085033</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           T           cl            y  \\\n",
       "count  5000.000000  5000.000000  5000.00000  5000.000000  5000.000000   \n",
       "mean      0.026132    -0.024901     0.20000     5.500000    25.201627   \n",
       "std       1.876621     2.335915     0.40004     2.872569    18.412630   \n",
       "min      -7.178571    -7.798972     0.00000     1.000000   -23.692425   \n",
       "25%      -1.232056    -1.585591     0.00000     3.000000    12.262571   \n",
       "50%       0.024851    -0.029248     0.00000     5.500000    22.595764   \n",
       "75%       1.275864     1.557381     0.00000     8.000000    35.658769   \n",
       "max       7.124257     7.803660     1.00000    10.000000    91.085033   \n",
       "\n",
       "                Tc  \n",
       "count  5000.000000  \n",
       "mean      1.900000  \n",
       "std       3.806954  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max      10.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xe = Xc.loc[5000:9999]\n",
    "Xe = Xe[['X1','X2','T','cl','y']]\n",
    "Xe.reset_index(drop=True, inplace=True)\n",
    "Xe.loc[0:3999,'T'] = 0\n",
    "Xe.loc[4000:4999,'T'] = 1\n",
    "Xe['Tc']= Xe['cl']*Xe['T']\n",
    "Xe['y'] = 5+5*Xe['X2'] + 2*Xe['Tc'] + 3*Xe['cl'] + Xe['X1'] \n",
    "\n",
    "Xe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.670\n",
      "Model:                            OLS   Adj. R-squared:                  0.670\n",
      "Method:                 Least Squares   F-statistic:                     4983.\n",
      "Date:                Sun, 20 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        14:15:57   Log-Likelihood:                -18886.\n",
      "No. Observations:                5000   AIC:                         3.778e+04\n",
      "Df Residuals:                    4997   BIC:                         3.780e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.2795      0.373     14.156      0.000       4.549       6.010\n",
      "Tc             2.1124      0.055     38.518      0.000       2.005       2.220\n",
      "cl             2.8925      0.073     39.598      0.000       2.749       3.036\n",
      "==============================================================================\n",
      "Omnibus:                        0.350   Durbin-Watson:                   1.979\n",
      "Prob(Omnibus):                  0.839   Jarque-Bera (JB):                0.392\n",
      "Skew:                          -0.011   Prob(JB):                        0.822\n",
      "Kurtosis:                       2.963   Cond. No.                         17.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "ye = Xe['y']\n",
    "Xe = Xe[['Tc','cl']]\n",
    "Xe = sm.add_constant(Xe)\n",
    "model = sm.OLS(ye, Xe)\n",
    "results = model.fit(cov_type=\"HC1\")\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Tarea 3**</font>\n",
    "\n",
    "<u> *Instrucciones* </u>\n",
    "\n",
    "Los resultados de los ejericicios propuestos se deben entregar como un notebook por correo electronico a *juan.caro@uni.lu* el dia 25/11 hasta las 21:00. \n",
    "\n",
    "Es importante considerar que el código debe poder ejecutarse en cualquier computadora con la data original del repositorio. Recordar la convencion para el nombre de archivo ademas de incluir en su documento titulos y encabezados por seccion. La unica data real a utilizar en parte de esta tarea es **charls.csv**. El resto de la data de la tarea debe ser generada a partir de las caracteristicas que se especifican. Las variables en **charls.csv** tienen la siguiente descripcion:\n",
    "\n",
    "- inid: identificador unico\n",
    "- wave: periodo de la encuesta (1-3)\n",
    "- cesd: puntaje en la escala de salud mental (0-30)\n",
    "- child: numero de hijos\n",
    "- drinkly: bebio alcohol en el ultimo mes (binario)\n",
    "- hrsusu: horas promedio trabajo semanal\n",
    "- hsize: tamano del hogar\n",
    "- intmonth: mes en que fue encuestado/a (1-12)\n",
    "- married: si esta casado/a (binario)\n",
    "- retired: si esta pensionado/a (binario)\n",
    "- schadj: años de escolaridad\n",
    "- urban: zona urbana (binario)\n",
    "- wealth: riqueza neta (miles RMB)\n",
    "- age: edad al entrar a la encuesta (no varia entre periodos)\n",
    "- bnrps: monto de pension publica (en RMB/mes)\n",
    "- dnrps: pension implementada en la provincia (binaria)\n",
    "- retage: fecha esperada de retiro (años desde la fecha de encuenta)\n",
    "- female: genero del encuestado\n",
    "- nrps: recibe pension publica\n",
    "\n",
    "Preguntas:\n",
    "\n",
    "Parte 1 - Experimentos\n",
    "\n",
    "Deben conceptualizar un experimento con el objetivo de estudiar posibles incentivos o estrategias para incrementar la asistencia a clases en estudiantes universitarios de la UdeC. El outcome del tratamiento es la proporcion promedio de estudiantes que asisten a clases. Todos los elementos del experimento deben ser definidos, respondiendo a las siguientes preguntas: \n",
    "\n",
    "1. Asumiendo la existencia de recursos disponibles e implementacion a nivel de estudiante, sugiera un tratamiento que pueda ser testeado a traves de un experimento aleatorizado controlado. Sea especifico en cuanto a los detalles del tratamiento (costos, materiales, duracion, etcetera).\n",
    "\n",
    "2. Defina los grupos de tratamiento y control para implementar su experimento. Describa en detalle el mecanismo de asignacion aleatorio que permite la comparacion entre grupos.\n",
    "\n",
    "3. Que metodo considera el mas apropiado para la estimacion del efecto promedio? (pre-test, pre-post test, Salomon 4 group). Justifique su respuesta en base a las ventajas y desventajas de cada metodo. \n",
    "\n",
    "4. Ahora suponga que no es posible implementar un experimento a nivel de estudiante, sino a nivel de clase. Como ajustaria los elementos de su experimento para poder ser implementado a nivel de cluster? Sea especifico respecto tanto del tratamiento como del metodo de asignacion aleatorio y potencial comparacion entre grupos de tratamiento y control.\n",
    "\n",
    "5. Suponga que en vez de un experimento, se planifica que sea un programa implementado a nivel de toda la Universidad. Como ajustaria los elementos descritos anteriormente para poder comparar el efecto de la intervencion.  \n",
    "\n",
    "Parte 2 - Estimacion de efectos promedio de tratamiento (data simulada)\n",
    "\n",
    "6. A partir de sus respuestas en Parte 1, genere data para 40 grupos (considere cada grupo como una clase) con 50 estudiantes cada uno (asuma que los estudiantes son asignados aleatoriamente a cada clase). Cada estudiante debe tener data de asistencia en un periodo, generando una variable binaria aleatoria talque la asistencia promedio a traves de todos los grupos es de 80%.\n",
    "\n",
    "7. Genere un mecanismo de asignacion aleatorio a nivel de estudiante y muestre que en la data generada permite que ambos grupos (tratamiento y control) tienen una asistencia promedio comparable.\n",
    "\n",
    "8. Genere un tratamiento que imcrementa la participacion en el grupo de tratamiento en 10 puntos porcentuales. Ademas en la data posterior al experimento, asuma que la participacion promedio cayo a 75%. Estime el efecto promedio del tratamiento usando solo post-test.\n",
    "\n",
    "9. Estime el efecto promedio del tratamiento usando pre-post test con la data generada. Muestre que el efecto es equivalente usando ambos metodos.\n",
    "\n",
    "10. Estime el efecto ajustando los errores estandar por cluster (la variable grupo representa cada clase). Cual es la diferencia entre ambas estimaciones? Explique porque es esperable (o no) encontrar diferencias entre ambos metodos.\n",
    "\n",
    "Parte 3 - Experimentos naturales \n",
    "\n",
    "Usando la data **charls.csv**, responda las siguientes preguntas relativas a experimentos naturales.\n",
    "\n",
    "11. Simule un experimento natural (e.g. intervencion de politica publica) tal que se reduce la proporcion de individuos con 3 hijos o mas que declaran beber alcohol en el tercer periodo a la mitad. Para ello, genere una variable de tratamiento (todos los individuos con mas de 2 hijos son parte de la intervencion), y una nueva variable llamada *sdrinlky*, talque es identica a *drinkly* en los periodos 1 y 2 , pero sustituya los valores aleatoriamente en el periodo 3 para generar el efecto esperado.\n",
    "\n",
    "12. Estime el efecto del tratamiento usando diferencias en diferencias, comparando entre los periodos 2 y 3. \n",
    "\n",
    "13. Compare el efecto del tratamiento generando grupos pseudo-equivalentes, en particular entre individuos solo con 3 hijos (tratamiento) y 2 hijos (control). \n",
    "\n",
    "14. Estime el efecto anterior usando la variable *married* como instrumento para determinar el efecto del tratamiento en la pregunta 12. Como se interpreta el efecto en este caso?\n",
    "\n",
    "15. Finalmente, asuma que la intervencion se implementa en todos los individuos. Genere una nueva variable de tratamiento un nueva variable llamada *tdrinkly* donde el efecto es una reduccion de 50% en la prevalencia de consumo de alcohol en toda la poblacion en el tercer periodo (identica a *drinkly* en los periodos 1 y 2). Genere una variable *cdrinkly* que es identica a *drinkly* en los periodos 1 y 2 y use la informacion de ambos periodos para predicir el valor esperado de *drinkly* en el tercer periodo, estos seran los valores de *cdrinkly* en el periodo 3 (contrafactual). Finalmente, estime el efecto de la intervencion en toda la poblacion comparando entre *tdrinkly* (datos reales) versus *cdrinkly* contrafactual.   "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
